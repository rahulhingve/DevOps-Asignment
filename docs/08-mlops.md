# 8. AI Model Deployment & MLOps

I've only used AI models locally with the help of Ollama so far, but I'm eager to learn more about deploying models in production environments. While I don't have practical experience with MLOps yet.

## My Current AI Experience

I've been experimenting with Ollama to run open-source LLMs locally, which has been great for:
- Testing different models like Llama 2 and Mistral
- Building simple applications that use AI for text generation
- Learning about prompt engineering



While I don't have professional MLOps experience yet, I'm excited to continue learning and implementing these practices in future projects!
